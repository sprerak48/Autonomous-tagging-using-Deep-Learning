{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Tags of Stackoveflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sprerak48/Autonomous-tagging-using-Deep-Learning/blob/Prerak/Predicting_Tags_of_Stackoveflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cu__J0E0lyrE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pqhqe4PN94uD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "biologyTable = pd.read_csv('../content/biology.csv',header=0)\n",
        "cookingTable = pd.read_csv('../content/cooking.csv',header=0)\n",
        "cryptoTable  = pd.read_csv('../content/crypto.csv',header=0)\n",
        "diyTable     = pd.read_csv('../content/diy.csv',header=0)\n",
        "roboticsTable= pd.read_csv('../content/robotics.csv',header=0)\n",
        "travelTable  = pd.read_csv('../content/travel.csv',header=0)\n",
        "physicsTable = pd.read_csv('../content/test.csv',header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_l5FFAIkebb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2261
        },
        "outputId": "080899ac-e340-4c64-ab1f-3cffcb4031ad"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#clean data using BeautifulSoup and Regex. First define functions:\n",
        "\n",
        "#cleans title of punctuation and sends to lower case (and optionally, stop words)\n",
        "def titles_to_wordlist(title, remove_stopwords=False ):\n",
        "    # Function to convert a document to a sequence of words,\n",
        "    # optionally removing stop words.  Returns a list of words.\n",
        "    # No need to remove HTML\n",
        "    # 1. Remove non-letters (and delete hyphens for now... this will have to be revised later)\n",
        "    title_text = re.sub(\"[^a-zA-Z0-9]\",\" \", title)\n",
        "    # 2. Convert words to lower case and split them\n",
        "    words = title_text.lower().split()\n",
        "    # 3. Optionally remove stop words (false by default)\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    # 4. Return a list of words\n",
        "    return(words)\n",
        "\n",
        "#cleans content of html (and optionally, stop words)\n",
        "def content_to_wordlist(content, remove_stopwords=False ):\n",
        "    # Function to convert a document to a sequence of words,\n",
        "    # optionally removing stop words.  Returns a list of words.\n",
        "    # 1. Remove HTML\n",
        "    content_text = BeautifulSoup(content, 'lxml').get_text()\n",
        "   \n",
        "    # 2. Remove non-letters (and delete hyphens for now... this will have to be revised later)\n",
        "    content_text = re.sub(\"[^a-zA-Z0-9]\",\" \", content_text)\n",
        "   \n",
        "    # 3. Convert words to lower case and split them\n",
        "    words = content_text.lower().split()\n",
        "   \n",
        "    # 4. Optionally remove stop words (false by default)\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "   \n",
        "    # 5. Return a list of words\n",
        "    return(words)\n",
        "    \n",
        "#splits tags into list of words\n",
        "def tags_to_wordlist(tags):\n",
        "    # Tags are already in lower case and grouped\n",
        "    # by using hyphens to incidate multiple words\n",
        "    #\n",
        "    # 1. Split the tags\n",
        "    words = tags.split()\n",
        "    #\n",
        "    # 2. Return a list of words\n",
        "    return(words)\n",
        "\n",
        "\n",
        "clean_content = content_to_wordlist( biologyTable[\"content\"][0],remove_stopwords=True )\n",
        "\n",
        "clean_titles = []\n",
        "clean_content = []\n",
        "clean_tags = []\n",
        "\n",
        "#form one large data frame with all the training set info to make text cleaning easier\n",
        "learningTables = [biologyTable, cookingTable, cryptoTable, diyTable, roboticsTable]\n",
        "\n",
        "print(\"Cleaning and parsing the training set StackExchange questions...\\n\")\n",
        "\n",
        "\n",
        "for table in learningTables:\n",
        "    num_records = table.shape[0]\n",
        "    for record in table.index:\n",
        "        # If the index is evenly divisible by 1000, print a message\n",
        "        if( (record+1)%1000 == 0 ):\n",
        "            print(\"Question %d of %d\\n\" % ( record+1, num_records ) )\n",
        "        clean_titles.append( titles_to_wordlist( table[\"title\"][record], remove_stopwords=True ))\n",
        "        clean_content.append( content_to_wordlist( table[\"content\"][record], remove_stopwords=True ))\n",
        "        clean_tags.append( tags_to_wordlist( table[\"tags\"][record] ))\n",
        "\n",
        "#not yet\n",
        "#allTables = pd.concat(learningTables)\n",
        "\n",
        "#begin parsing the learning tables into bag-of-words matrices\n",
        "count_vect = CountVectorizer()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning and parsing the training set StackExchange questions...\n",
            "\n",
            "Question 1000 of 13196\n",
            "\n",
            "Question 2000 of 13196\n",
            "\n",
            "Question 3000 of 13196\n",
            "\n",
            "Question 4000 of 13196\n",
            "\n",
            "Question 5000 of 13196\n",
            "\n",
            "Question 6000 of 13196\n",
            "\n",
            "Question 7000 of 13196\n",
            "\n",
            "Question 8000 of 13196\n",
            "\n",
            "Question 9000 of 13196\n",
            "\n",
            "Question 10000 of 13196\n",
            "\n",
            "Question 11000 of 13196\n",
            "\n",
            "Question 12000 of 13196\n",
            "\n",
            "Question 13000 of 13196\n",
            "\n",
            "Question 1000 of 15404\n",
            "\n",
            "Question 2000 of 15404\n",
            "\n",
            "Question 3000 of 15404\n",
            "\n",
            "Question 4000 of 15404\n",
            "\n",
            "Question 5000 of 15404\n",
            "\n",
            "Question 6000 of 15404\n",
            "\n",
            "Question 7000 of 15404\n",
            "\n",
            "Question 8000 of 15404\n",
            "\n",
            "Question 9000 of 15404\n",
            "\n",
            "Question 10000 of 15404\n",
            "\n",
            "Question 11000 of 15404\n",
            "\n",
            "Question 12000 of 15404\n",
            "\n",
            "Question 13000 of 15404\n",
            "\n",
            "Question 14000 of 15404\n",
            "\n",
            "Question 15000 of 15404\n",
            "\n",
            "Question 1000 of 10432\n",
            "\n",
            "Question 2000 of 10432\n",
            "\n",
            "Question 3000 of 10432\n",
            "\n",
            "Question 4000 of 10432\n",
            "\n",
            "Question 5000 of 10432\n",
            "\n",
            "Question 6000 of 10432\n",
            "\n",
            "Question 7000 of 10432\n",
            "\n",
            "Question 8000 of 10432\n",
            "\n",
            "Question 9000 of 10432\n",
            "\n",
            "Question 10000 of 10432\n",
            "\n",
            "Question 1000 of 25918\n",
            "\n",
            "Question 2000 of 25918\n",
            "\n",
            "Question 3000 of 25918\n",
            "\n",
            "Question 4000 of 25918\n",
            "\n",
            "Question 5000 of 25918\n",
            "\n",
            "Question 6000 of 25918\n",
            "\n",
            "Question 7000 of 25918\n",
            "\n",
            "Question 8000 of 25918\n",
            "\n",
            "Question 9000 of 25918\n",
            "\n",
            "Question 10000 of 25918\n",
            "\n",
            "Question 11000 of 25918\n",
            "\n",
            "Question 12000 of 25918\n",
            "\n",
            "Question 13000 of 25918\n",
            "\n",
            "Question 14000 of 25918\n",
            "\n",
            "Question 15000 of 25918\n",
            "\n",
            "Question 16000 of 25918\n",
            "\n",
            "Question 17000 of 25918\n",
            "\n",
            "Question 18000 of 25918\n",
            "\n",
            "Question 19000 of 25918\n",
            "\n",
            "Question 20000 of 25918\n",
            "\n",
            "Question 21000 of 25918\n",
            "\n",
            "Question 22000 of 25918\n",
            "\n",
            "Question 23000 of 25918\n",
            "\n",
            "Question 24000 of 25918\n",
            "\n",
            "Question 25000 of 25918\n",
            "\n",
            "Question 1000 of 2771\n",
            "\n",
            "Question 2000 of 2771\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LGIr9JQGFv29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/miljan/predicting-tags-for-stackoverflow/notebook\n",
        "\n",
        "\n",
        "https://github.com/Meghashyam5/Stack-Tag-Predictor/blob/master/Stack%20Tag%20Predictor.ipynb\n",
        "\n",
        "https://medium.com/datadriveninvestor/predicting-tags-for-the-questions-in-stack-overflow-29438367261e\n",
        "\n",
        "https://www.kaggle.com/rinalin/predicting-stackflow-tags/data\n"
      ]
    },
    {
      "metadata": {
        "id": "-qyR_qjVGNKU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/abehmiel/predicting-stackexchange-physics-tags/code\n",
        "\n",
        "https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags/data\n"
      ]
    },
    {
      "metadata": {
        "id": "hHCQaPxR1YFc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stacklite datasets prediction of tags"
      ]
    },
    {
      "metadata": {
        "id": "iHJqfkZ6xBmk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c transfer-learning-on-stack-exchange-tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LcRRN34wxU-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip biology.csv.zip\n",
        "!unzip cooking.csv.zip\n",
        "!unzip crypto.csv.zip\n",
        "!unzip diy.csv.zip\n",
        "!unzip kaggle.csv.zip\n",
        "!unzip robotics.csv.zip\n",
        "!unzip sample_submission.csv.zip\n",
        "!unzip test.csv.zip\n",
        "!unzip travel.csv.zipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iCWPIXzyYJY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import nltk # natural language processing\n",
        "import re # regular expression\n",
        "from bs4 import BeautifulSoup #scraping HTML\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns # visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from string import punctuation\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../content\"]).decode(\"utf8\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-mE6TjLYxdFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "biology = pd.read_csv(\"../content/biology.csv\")\n",
        "cooking = pd.read_csv(\"../content/cooking.csv\")\n",
        "crypto = pd.read_csv(\"../content/crypto.csv\")\n",
        "diy = pd.read_csv(\"../content/diy.csv\")\n",
        "robotics = pd.read_csv(\"../content/robotics.csv\")\n",
        "travel = pd.read_csv(\"../content/travel.csv\")\n",
        "test = pd.read_csv(\"../content/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xf28Z-Rjzcce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#raw = pd.concat([biology,cooking,crypto,diy,robotics,travel],axis = 0, ignore_index =True)\n",
        "raw = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8A9R9qxzn-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be29f6df-7abb-4dab-e507-fd0e86d87cdc"
      },
      "cell_type": "code",
      "source": [
        "# Simple Statistics\n",
        "print(\"This dataset has in total {} rows.\".format(raw.shape[0]))\n",
        "#print(\"out of which, {} rows come from train dataset and {} rows come from test dataset.\".format(raw[raw['source']=='train'].shape[0],raw[raw['source']=='test'].shape[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This dataset has in total 81926 rows.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cy12GkO_0ijm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_content(s):\n",
        "    emphasize = []\n",
        "    header = []\n",
        "    link = []\n",
        "    content = \"\"\n",
        "    soup = BeautifulSoup(s,'html.parser')\n",
        "    content = soup.get_text()\n",
        "    return pd.Series({'content_parsed':content})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZV_MZ0y603EZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw = pd.concat([raw,raw['content'].apply(parse_content)],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "edtfJdh_1i1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bc8ad08b-7695-4f96-b53f-577593aaa348"
      },
      "cell_type": "code",
      "source": [
        "test[1:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>What is your simplest explanation of the strin...</td>\n",
              "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Lie theory, Representations and particle physics</td>\n",
              "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Will Determinism be ever possible?</td>\n",
              "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>Hamilton's Principle</td>\n",
              "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              title  \\\n",
              "1   2  What is your simplest explanation of the strin...   \n",
              "2   3   Lie theory, Representations and particle physics   \n",
              "3   7                 Will Determinism be ever possible?   \n",
              "4   9                               Hamilton's Principle   \n",
              "\n",
              "                                             content  \n",
              "1  <p>How would you explain string theory to non ...  \n",
              "2  <p>This is a question that has been posted at ...  \n",
              "3  <p>What are the main problems that we need to ...  \n",
              "4  <p>Hamilton's principle states that a dynamic ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "52tZT5dt1yCJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "def strip_punctuation(s):\n",
        "    return ''.join(c for c in s if c not in punctuation)\n",
        "#Building NLTK pipelines\n",
        "def td_idf_matrix(dataset):\n",
        "    dataset['all_text'] = dataset['title'] + dataset['content_parsed'] \n",
        "    dataset['all_text'] = dataset['all_text'].apply(lambda x: str.lower(x).replace('\\n',' '))\n",
        "    mydoclist = [strip_punctuation(doc) for doc in dataset['all_text'].tolist()]\n",
        "    count_vectorizer = CountVectorizer(stop_words='english',lowercase=True,analyzer='word')\n",
        "    term_freq_matrix = count_vectorizer.fit_transform(mydoclist)\n",
        "    tfidf = TfidfTransformer(norm=\"l2\")\n",
        "    tfidf.fit(term_freq_matrix)\n",
        "    tf_idf_matrix = tfidf.transform(term_freq_matrix)\n",
        "    pos_to_word = dict([[v,k] for k,v in count_vectorizer.vocabulary_.items()])\n",
        "    return tf_idf_matrix, pos_to_word\n",
        "\n",
        "tf_idf_matrix, pos_to_word = td_idf_matrix(raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5R6h56y_2YWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def importance_list_row(sparse_row,n_importance):\n",
        "    importance_list = [0]*n_importance\n",
        "    for i in range(0,n_importance): \n",
        "        ind =  sparse_row.indices[sparse_row.data.argmax(axis=0)] if sparse_row.nnz else 0\n",
        "        importance_list[i] = pos_to_word[ind]\n",
        "        sparse_row[0,ind] = 0\n",
        "    return importance_list\n",
        "\n",
        "\n",
        "def importance_list(sparse_matrix,n_importance):\n",
        "    n_row = sparse_matrix.shape[0]\n",
        "    importance_lists = [0]*n_row\n",
        "    for row in range(0,n_row):\n",
        "        importance_lists[row] = importance_list_row(sparse_matrix[row],n_importance)\n",
        "    return importance_lists "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yCniY64v2YRU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#n_importance = 2\n",
        "#predict = importance_list(tf_idf_matrix,n_importance)\n",
        "#predict_vs_actual = pd.DataFrame({'predict':predict})\n",
        "#predict_vs_actual['predict'] = predict_vs_actual['predict'].apply(lambda x: \"\".join(chr+\" \") for char in x)\n",
        "#predict_vs_actual[0:50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Qf8I2q86P0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fd71cee7-fcd5-4261-fdd0-5213f3716368"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "raw['all_text'] = raw['all_text'].apply(strip_punctuation)\n",
        "raw['text_token'] = raw['all_text'].apply(nltk.word_tokenize)\n",
        "raw['text_token'] = raw['all_text'].apply(nltk.word_tokenize)\n",
        "raw['text_token'] = raw['text_token'].apply(lambda x:[lemmatizer.lemmatize(t) for t in x])\n",
        "raw['text_pos'] = raw['text_token'].apply(nltk.pos_tag)\n",
        "raw['text_nouns'] = raw['text_pos'].apply(lambda x: [pair[0] for pair in x if pair[1] in (\"NN\",\"NNS\",\"JJ\")])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BM4vM0j38ajU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw['text_bigram'] = raw['text_pos'].apply(nltk.bigrams)\n",
        "raw['text_bigram'] = raw['text_bigram'].apply(list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSu6CWypOTcL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw['word_pair'] = raw['text_bigram'].apply(findPair)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVUo0w_9OTRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d65a9b58-6539-48b7-b871-0fba23f3f799"
      },
      "cell_type": "code",
      "source": [
        "raw[0:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>content_parsed</th>\n",
              "      <th>all_text</th>\n",
              "      <th>text_token</th>\n",
              "      <th>text_pos</th>\n",
              "      <th>text_nouns</th>\n",
              "      <th>text_bigram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What is spin as it relates to subatomic partic...</td>\n",
              "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
              "      <td>I often hear about subatomic particles having ...</td>\n",
              "      <td>what is spin as it relates to subatomic partic...</td>\n",
              "      <td>[what, is, spin, a, it, relates, to, subatomic...</td>\n",
              "      <td>[(what, WP), (is, VBZ), (spin, VBG), (a, DT), ...</td>\n",
              "      <td>[particlesi, subatomic, particle, property, sp...</td>\n",
              "      <td>[((what, WP), (is, VBZ)), ((is, VBZ), (spin, V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>What is your simplest explanation of the strin...</td>\n",
              "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
              "      <td>How would you explain string theory to non phy...</td>\n",
              "      <td>what is your simplest explanation of the strin...</td>\n",
              "      <td>[what, is, your, simplest, explanation, of, th...</td>\n",
              "      <td>[(what, WP), (is, VBZ), (your, PRP$), (simples...</td>\n",
              "      <td>[simplest, explanation, string, theoryhow, the...</td>\n",
              "      <td>[((what, WP), (is, VBZ)), ((is, VBZ), (your, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Lie theory, Representations and particle physics</td>\n",
              "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
              "      <td>This is a question that has been posted at man...</td>\n",
              "      <td>lie theory representations and particle physic...</td>\n",
              "      <td>[lie, theory, representation, and, particle, p...</td>\n",
              "      <td>[(lie, NN), (theory, NN), (representation, NN)...</td>\n",
              "      <td>[lie, theory, representation, particle, physic...</td>\n",
              "      <td>[((lie, NN), (theory, NN)), ((theory, NN), (re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Will Determinism be ever possible?</td>\n",
              "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
              "      <td>What are the main problems that we need to sol...</td>\n",
              "      <td>will determinism be ever possiblewhat are the ...</td>\n",
              "      <td>[will, determinism, be, ever, possiblewhat, ar...</td>\n",
              "      <td>[(will, MD), (determinism, VB), (be, VB), (eve...</td>\n",
              "      <td>[main, problem, laplace, determinism, correct,...</td>\n",
              "      <td>[((will, MD), (determinism, VB)), ((determinis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>Hamilton's Principle</td>\n",
              "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
              "      <td>Hamilton's principle states that a dynamic sys...</td>\n",
              "      <td>hamiltons principlehamiltons principle states ...</td>\n",
              "      <td>[hamilton, principlehamiltons, principle, stat...</td>\n",
              "      <td>[(hamilton, NN), (principlehamiltons, NNS), (p...</td>\n",
              "      <td>[hamilton, principlehamiltons, state, dynamic,...</td>\n",
              "      <td>[((hamilton, NN), (principlehamiltons, NNS)), ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              title  \\\n",
              "0   1  What is spin as it relates to subatomic partic...   \n",
              "1   2  What is your simplest explanation of the strin...   \n",
              "2   3   Lie theory, Representations and particle physics   \n",
              "3   7                 Will Determinism be ever possible?   \n",
              "4   9                               Hamilton's Principle   \n",
              "\n",
              "                                             content  \\\n",
              "0  <p>I often hear about subatomic particles havi...   \n",
              "1  <p>How would you explain string theory to non ...   \n",
              "2  <p>This is a question that has been posted at ...   \n",
              "3  <p>What are the main problems that we need to ...   \n",
              "4  <p>Hamilton's principle states that a dynamic ...   \n",
              "\n",
              "                                      content_parsed  \\\n",
              "0  I often hear about subatomic particles having ...   \n",
              "1  How would you explain string theory to non phy...   \n",
              "2  This is a question that has been posted at man...   \n",
              "3  What are the main problems that we need to sol...   \n",
              "4  Hamilton's principle states that a dynamic sys...   \n",
              "\n",
              "                                            all_text  \\\n",
              "0  what is spin as it relates to subatomic partic...   \n",
              "1  what is your simplest explanation of the strin...   \n",
              "2  lie theory representations and particle physic...   \n",
              "3  will determinism be ever possiblewhat are the ...   \n",
              "4  hamiltons principlehamiltons principle states ...   \n",
              "\n",
              "                                          text_token  \\\n",
              "0  [what, is, spin, a, it, relates, to, subatomic...   \n",
              "1  [what, is, your, simplest, explanation, of, th...   \n",
              "2  [lie, theory, representation, and, particle, p...   \n",
              "3  [will, determinism, be, ever, possiblewhat, ar...   \n",
              "4  [hamilton, principlehamiltons, principle, stat...   \n",
              "\n",
              "                                            text_pos  \\\n",
              "0  [(what, WP), (is, VBZ), (spin, VBG), (a, DT), ...   \n",
              "1  [(what, WP), (is, VBZ), (your, PRP$), (simples...   \n",
              "2  [(lie, NN), (theory, NN), (representation, NN)...   \n",
              "3  [(will, MD), (determinism, VB), (be, VB), (eve...   \n",
              "4  [(hamilton, NN), (principlehamiltons, NNS), (p...   \n",
              "\n",
              "                                          text_nouns  \\\n",
              "0  [particlesi, subatomic, particle, property, sp...   \n",
              "1  [simplest, explanation, string, theoryhow, the...   \n",
              "2  [lie, theory, representation, particle, physic...   \n",
              "3  [main, problem, laplace, determinism, correct,...   \n",
              "4  [hamilton, principlehamiltons, state, dynamic,...   \n",
              "\n",
              "                                         text_bigram  \n",
              "0  [((what, WP), (is, VBZ)), ((is, VBZ), (spin, V...  \n",
              "1  [((what, WP), (is, VBZ)), ((is, VBZ), (your, P...  \n",
              "2  [((lie, NN), (theory, NN)), ((theory, NN), (re...  \n",
              "3  [((will, MD), (determinism, VB)), ((determinis...  \n",
              "4  [((hamilton, NN), (principlehamiltons, NNS)), ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "fh1R2TnyO2v2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def findPair(l):\n",
        "    result = []\n",
        "    for pair in l:\n",
        "        if pair[1][1] in ('NN','NNS') and pair[0][1] in ('NN','NNS','JJ'):\n",
        "            result.append(pair[0][0]+\" \"+pair[1][0])\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtgT2cZmO_Om",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mydoclist = raw['text_nouns'].apply(\" \".join).tolist()\n",
        "#mydoclist[0:5]\n",
        "count_vectorizer = CountVectorizer(stop_words='english',lowercase=True,analyzer='word',ngram_range=(1,1))\n",
        "term_freq_matrix = count_vectorizer.fit_transform(mydoclist)\n",
        "tfidf = TfidfTransformer(norm=\"l2\")\n",
        "tfidf.fit(term_freq_matrix)\n",
        "tf_idf_matrix = tfidf.transform(term_freq_matrix)\n",
        "pos_to_word = dict([[v,k] for k,v in count_vectorizer.vocabulary_.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BgYLfWA-PPRi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_importance = 3\n",
        "predict = importance_list(tf_idf_matrix,n_importance)\n",
        "predict_vs_actual = pd.DataFrame({'tags':predict,'id':raw['id']})\n",
        "predict_vs_actual['tags'] = predict_vs_actual['tags'].apply(\" \".join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_o0frB0PeDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "17755252-5d2e-407c-d3a1-67ed84c5239d"
      },
      "cell_type": "code",
      "source": [
        "predict_vs_actual[0:100]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>spin particlesi spinning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>theoryhow simplest plausible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>group lie representation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>determinism laplace main</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>principlehamiltons stationary action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13</td>\n",
              "      <td>sound producedive clue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15</td>\n",
              "      <td>string theory group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>17</td>\n",
              "      <td>sky sunriseset blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19</td>\n",
              "      <td>energy collision calculatedphysicists</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>21</td>\n",
              "      <td>monte carlo method</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>24</td>\n",
              "      <td>bike wheel turn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>26</td>\n",
              "      <td>projectile vanderpool electromagnetic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>27</td>\n",
              "      <td>particle measurement collapse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>29</td>\n",
              "      <td>average trip mile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>31</td>\n",
              "      <td>lay special theory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>32</td>\n",
              "      <td>whirlvortex sinkbathtubthere myth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>35</td>\n",
              "      <td>magnet energy pole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>37</td>\n",
              "      <td>theory worldphysicists einsteinlike</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>41</td>\n",
              "      <td>physicist field theory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>49</td>\n",
              "      <td>capacitive touchpad touchscreen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>52</td>\n",
              "      <td>pole repel magnet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>62</td>\n",
              "      <td>lhc longthe circular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>68</td>\n",
              "      <td>polarised tape colour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>71</td>\n",
              "      <td>gouy phase tem01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>72</td>\n",
              "      <td>therapy cancer treatment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>73</td>\n",
              "      <td>yangbaxter solution mathematician</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>75</td>\n",
              "      <td>mnemonic resistant failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>78</td>\n",
              "      <td>teacher neutron otheri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>79</td>\n",
              "      <td>entangled experiment entanglement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>83</td>\n",
              "      <td>uncertainty shot noise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>218</td>\n",
              "      <td>insightfulimpressive adultssimilar adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>222</td>\n",
              "      <td>software calculationswhat symbolic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>228</td>\n",
              "      <td>ring aerotrim gyroscope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>234</td>\n",
              "      <td>mathematics student curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>236</td>\n",
              "      <td>positronium element theyre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>237</td>\n",
              "      <td>irregular lab nonhollow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>239</td>\n",
              "      <td>object iron friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>252</td>\n",
              "      <td>manybody quantum body</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>257</td>\n",
              "      <td>accelerator synchrotron tevatron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>258</td>\n",
              "      <td>domino tippage angle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>268</td>\n",
              "      <td>capillary vegetationeach pullpress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>270</td>\n",
              "      <td>clothing wear white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>271</td>\n",
              "      <td>explanation precession diagram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>272</td>\n",
              "      <td>counterintuitive physicsi good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>286</td>\n",
              "      <td>arentdoes intuitive rotation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>290</td>\n",
              "      <td>wing airplane bernoulli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>296</td>\n",
              "      <td>energy conservedin caveat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>300</td>\n",
              "      <td>model workglobal subgridscale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>303</td>\n",
              "      <td>water disturbedwhen sound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>304</td>\n",
              "      <td>pitch firework hertz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>305</td>\n",
              "      <td>radiation photoelectric electron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>312</td>\n",
              "      <td>physic startedi rigor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>317</td>\n",
              "      <td>measurement outcome single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>321</td>\n",
              "      <td>centripetal blanket gravity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>326</td>\n",
              "      <td>angular momentum torque</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>328</td>\n",
              "      <td>number suggestion angular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>331</td>\n",
              "      <td>period precession precessionim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>335</td>\n",
              "      <td>electricity instantaneousmy delay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>339</td>\n",
              "      <td>ray coefficient refraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>340</td>\n",
              "      <td>peephole person door</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                      tags\n",
              "0     1                  spin particlesi spinning\n",
              "1     2              theoryhow simplest plausible\n",
              "2     3                  group lie representation\n",
              "3     7                  determinism laplace main\n",
              "4     9      principlehamiltons stationary action\n",
              "5    13                    sound producedive clue\n",
              "6    15                       string theory group\n",
              "7    17                       sky sunriseset blue\n",
              "8    19     energy collision calculatedphysicists\n",
              "9    21                        monte carlo method\n",
              "10   24                           bike wheel turn\n",
              "11   26     projectile vanderpool electromagnetic\n",
              "12   27             particle measurement collapse\n",
              "13   29                         average trip mile\n",
              "14   31                        lay special theory\n",
              "15   32         whirlvortex sinkbathtubthere myth\n",
              "16   35                        magnet energy pole\n",
              "17   37       theory worldphysicists einsteinlike\n",
              "18   41                    physicist field theory\n",
              "19   49           capacitive touchpad touchscreen\n",
              "20   52                         pole repel magnet\n",
              "21   62                      lhc longthe circular\n",
              "22   68                     polarised tape colour\n",
              "23   71                          gouy phase tem01\n",
              "24   72                  therapy cancer treatment\n",
              "25   73         yangbaxter solution mathematician\n",
              "26   75                mnemonic resistant failure\n",
              "27   78                    teacher neutron otheri\n",
              "28   79         entangled experiment entanglement\n",
              "29   83                    uncertainty shot noise\n",
              "..  ...                                       ...\n",
              "70  218  insightfulimpressive adultssimilar adult\n",
              "71  222        software calculationswhat symbolic\n",
              "72  228                   ring aerotrim gyroscope\n",
              "73  234            mathematics student curriculum\n",
              "74  236                positronium element theyre\n",
              "75  237                   irregular lab nonhollow\n",
              "76  239                        object iron friend\n",
              "77  252                     manybody quantum body\n",
              "78  257          accelerator synchrotron tevatron\n",
              "79  258                      domino tippage angle\n",
              "80  268        capillary vegetationeach pullpress\n",
              "81  270                       clothing wear white\n",
              "82  271            explanation precession diagram\n",
              "83  272            counterintuitive physicsi good\n",
              "84  286              arentdoes intuitive rotation\n",
              "85  290                   wing airplane bernoulli\n",
              "86  296                 energy conservedin caveat\n",
              "87  300             model workglobal subgridscale\n",
              "88  303                 water disturbedwhen sound\n",
              "89  304                      pitch firework hertz\n",
              "90  305          radiation photoelectric electron\n",
              "91  312                     physic startedi rigor\n",
              "92  317                measurement outcome single\n",
              "93  321               centripetal blanket gravity\n",
              "94  326                   angular momentum torque\n",
              "95  328                 number suggestion angular\n",
              "96  331            period precession precessionim\n",
              "97  335         electricity instantaneousmy delay\n",
              "98  339                ray coefficient refraction\n",
              "99  340                      peephole person door\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "qckdP-6YPiLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_vs_actual.to_csv(\"predicted.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}